\section{Diffusion \& Foundation models}

\subsection*{Denoising Diffusion Probability Models}

\textbf{Adv} VAE/AR low quality, GANs unstable to train, NF must be invertible. Diffusion model none of these.

\textbf{NN for denoising}: usually UNet with conditioning on $t$.

\textbf{Conditioning} (1) train on just images of cats (2) classifier guidance: nudge noise in direction of cats with $\omega\cdot\nabla$classif, but problems if limited or errorful classif, and must train classif together with NN (3) classifier-free guidance: condition NN but still include 20\% of unconditional for diversity and quality tradeoff.

\textbf{Latent diffusion models}: denoise in smaller latent space with more semantics, so first need to train an autoencoder, then use frozen decoder to reconstruct image. App: Stable Diff, DALL-E 3, SORA.

Text-to-image limited, so do feature modulation on top of text embeddings. Can use also for photo relighting (IC-Light).

\textbf{Zero-Conv} in \textbf{ControlNet} is alternative feat mod $y_c = NN_{\text{frozen}}(x) + Z_{2, \text{init}=0}(NN2_{\text{trainable}}(x + Z_{2, \text{init}=0}(c)))$, $Z_1$ and $Z_2$ are 1x1 conv.

\subsection*{DDPM algorithm}

\textbf{Adding noise} markovian: $q(x_t|x_{t-1})=N(\sqrt{\alpha_t}x_{t-1}, (1-\alpha_t)I)$, for $q(x_t|x_0)$ see loss

\textbf{Loss} $||\epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t)||_2^2$

\textbf{Sampl} $x_{t-1} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t, t)) + \sigma_t z$

where $\alpha_t = 1-\beta_t$, $\bar{\alpha}_t = \prod_{i=1}^{t} \alpha_i$, $\epsilon, x_T, z \sim N(0,I)$, if $t=1 \rightarrow z=0$.

\textbf{Deriv} $\log p(x) \geq ELBO_\theta(x) =
\mathbb{E}_{q(x_1|x_0)} [\allowbreak \log p_\theta(x_0 | x_1)]
- \mathcal{D}_{\text{KL}}(\allowbreak q(x_T | x_0) \,\|\, p(x_T))
+ \sum_{t=2}^{T} \allowbreak \mathbb{E}_{q(x_t | x_0)} \left[\allowbreak
\mathcal{D}_{\text{KL}}\left(q(x_{t-1} | x_t, x_0) \,\|\, p_\theta(x_{t-1} | x_t) \right) \right]$, with $q(x_{t-1}|x_t,x_0)$ is Gaussian

\subsection*{Foundation models}

\textbf{(1 gen)}: general enc + task dec, NLP = ELMO BERT ERNIE, vision = ViT \textit{(imgs are tokens)}, MaskedAutoEncoder/MAE \textit{(reconstruct after removing some tokens)}, ViTpose and Sapiens \textit{(humans)}, SegmentAnything/SAM, CLIP \textit{(features as conditions, shared space with contrastive learning by pushing high cos sim. of similar text+img pairs)} DINOv2 \textit{(self-superv, knowledge distilled from student/teacher with local/global view, backprop diff(t,s) through student and update teacher}, MassivelyMultimodalMaskedModeling/4M; \textbf{(2 gen)}: general model + task finetune, NLP = GPT-3, diffusion = DreamBooth \textit{(text2img, easily finetune with new token to represent ``my dog'')} Zero-1-to-3 \textit{(3D view synthesis by cond on img and camera params)} SiTH \textit{(like 0123 but also works well on humans)}; \textbf{(3 gen)} NLP = LLMs.
