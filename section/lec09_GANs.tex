\section{GANs, implicit model, neural sampler, likelihood-free model}

\textbf{Intuition} Likelihood not good indicator for generation, can be independent: \(\ln [0.01 p_{\text{true}}+0.99 q_{\text{noise}}] \geq \ln [0.01 p_{\text{true}}]=\ln p({x})-\ln 100\).

\textbf{Pros} (1) Highly expressive, (2) Density function not defined or intractable.
 \textbf{Cons} Lack of theory and learning algo cmp to explicit models.


\textbf{Idea} Two-player game. \textbf{Generator} fool the discriminator with real-looking images \(G: \mathbb{R}^{Q} \to \mathbb{R}^{D}\) from Gaussian noise to images. \textbf{Discriminator} distinguish btw real and fake img \(D: \mathbb{R}^{D} \to [0,1]\).

\textbf{Obj} \( \underset{G}{\operatorname{min}} \underset{D}{\operatorname{max}} {V}_{{G}, {D}}=\ln D({x}) + \ln (1-D(\hat{{x}}))\)

\textbf{Optim} \(D^{*} = \underset{D}{\operatorname{argmax}} {V}_{{G}, {D}} = \frac{p_{\text{D}}({x})}{p_{\text {D}}({x})+p_{\text {M}}({x})}\). 
% 
Jensen-Shannon Div \(\JS(p \| q\ := [ {D}_{K L}(p \| \frac{p+q}{2})+{D}_{K L}(q \| \frac{p+q}{2}) ]/2\), \(\JS(p \| q)=0\) iff \(p_{\text {D}}\equiv p_{\text {M}}\).

\(V_{G, D^{*}} =  -\ln 4+2 \JS (p_{d}({x}) \| p_{m}({x}))\), global optim if \(p_{\text {D}}({x})\equiv p_{\text {M}}({x})\).

If \(G,D\) enough capacity, each step can reach \(D^*\),  update \(p_{\text {M}}\) directly instead of its param, then \(V(p_{\text{M}}, D^{*})\) is convex, global optim can reach and \( \propto \sup _{D} \mathbb{E}_{p_{\text {M}}({x})} \ln (1-D({x})) d {x}\).

(1) In practice pptim \(D\) in inner-loop is computationally prohibitive and lead to overfitting on finite datasets.

(2) \textbf{Aim} keep \(D\) near optimum and \(G\) changes only slowly: \(k\) steps of optim \(D\) (typically \(k \in\{1, \ldots, 5\}\)), 1 step of optim \(G\) with small lr. 

(3) \(\log (1-D(G(z)))\) near zero \(\to\) smaller \(\nabla\) \(\Rightarrow\) gradient ascent \(\max _{G} \mathbb{E}_{z \sim p_{z}(z)}[\ln (D(G(z)))]\).

% Theoretical analysis shows that this minimax game recovers = \(p_{\text {M}}=p_{d a t a}\) if \(G\) and \(D\) are given enough capacity and  assuming that \(D^*\) can be reached. 

\subsection*{Issues}

1. Difficult to train, Mode collapse (no sample diversity), saddle point in dual energy landscape. Sol: unrolled GAN.

2. Low dim manifolds in high dim prob space have little overlap. \(D\) of vanilla GAN saturates if no overlapping support. \(\JS\) only measures similarity, not `work' required from \(p_{\text {M}}\) to  \(p_{\text {D}}\). Sol: Wasserstein GAN. GAN can be generalized to entire family of div.

\subsection*{Pros and Cons}
\textbf{Pros} (1) A wide variety of functions and distributions can be modeled (flexibility). (2) Only backprop when training, no sampling, stochastic optim. (3)  No approximation to likelihood required as in VAEs. (4) Samples more realistic than other DGMs.

\textbf{Cons} (1) No explicit \(p_{M}\). (2) no direct means to evaluate likelihood (3) Careful balancing \(G\) and \(D\) during training .

\subsection*{Applications}

\textbf{Pix2Pix} cond GAN, Obj: \(\mathcal{L}(G, D)=\mathcal{L}_{c G A N}(G, D)+\lambda \mathcal{L}_{L 1}(G)\), \(\mathcal{L}_{{cGAN}}(G, D)=\mathbb{E}_{x, y}[\ln D(x, y)]+\mathbb{E}_{x, z}[1-\ln D(x, G(x, z))]\), \(x\) conditions, \(\mathcal{L}_{L 1}(G)=\mathbb{E}_{x, y, z}[\|y-G(x, z)\|_{1}]\) reconstruction loss. requires paired images as training data. Translate samples from two side.

\textbf{CycleGAN} unpaired image translation: Two conditional GANs \(\mathcal{L}(G, F, D_{X}, D_{Y})=\mathcal{L}_{G A N}(G, D_{Y}, X, Y)+\mathcal{L}_{G A N}(F, D_{X}, Y, X)+\lambda \mathcal{L}_{\text {cyc }}(G, F)\), \(L_{cyc} = .=\mathbb{E}_{x \sim p_{\text {D}}(x)}\|\| F(G(x))-x \|_{1}]+\mathbb{E}_{y \sim p_{\text {D}}(y)}[\|G(F(y))-y\|_{1}]\). Transfer and Transfer back.

\textbf{GauGAN} Given semantic seg and reference style, synthesize image. Problem with pix2pix: Unconditional norm layer in \(G\) “washes away” information of semantic labels. Sol: Spatial cond norm \(\gamma_{c, y, x}^{i}({m}) \frac{h_{n, c, y, x}^{i}-\mu_{c}^{i}}{\sigma_{c}^{i}}+\beta_{c, y, x}^{i}({m})\)

\textbf{Progressive Growing of GAN}s:  Grow the generator and discriminator resolution by adding layers during training.

\textbf{StyleGAN}
